
\section{À propos}

De nos jours, la musique est devenue un vaste sujet de recherche scientifique. Les branches de la musique se développent à travers divers domaines tels que, l'analyse musicale mélangée avec la modélisation mathématique, l’histoire avec l’ethnomusicologie, l’acoustique avec la physique, la composition avec la programmation, etc. En empruntant cette voie interdisciplinaire, on va lier la musique aux autres sciences, afin ainsi de progresser vers un nouveau point de vue et de présenter des résultats innovants.

Dans la branche de la composition musicale, l’étude de la nature du son a été spécialement développée en produisant diverses techniques guidées par des phénomènes physiques. Une série d'outils de traitement du son basés sur des phénomènes physiques sont étiquetés sous une branche appelée analyse-synthèse du son. Dans cette branche, un ensemble de disciplines scientifiques se contracte dans un seul but, de comprendre la musique et la nature sonore. À travers l’analyse sonore, nous procédons à la synthèse. De la science nous alons vers l'art. Le nom d'analyse-synthèse exprime ce principe, d’observation (analyse). Cela permet de procéder au traitement du son et aboutir à un nouveau produit sonore (synthèse). Le nom, est traduit littérairement au traitement spectral, où l’étape d’analyse transfère un son du domaine temporel au domaine fréquentiel. L'analyse présente les informations spectrales d'un son à une certaine période du temps. L'outil de synthèse inverse le processus, il transfère le son du domaine fréquentiel vers le domaine temporel, ce qui produit comme résultat, la forme de signal d'onde conventionnelle.

Les outils d'analyse-synthèse sont initialement conçus pour aider les compositeurs ou les artistes en particulier de la composition contemporaine. Ils peuvent servir notamment, pour l'utilisation de séquences générées par l’ordinateur sur les œuvres de Stockhousen ou bien pour l’analyse spectrale assistée par ordinateur pour répondre aux besoins des compositeurs spectraux, tel que Gerard Grisey, Tristan Murail, etc. Pour autant, les résultats ou les techniques ne sont pas nécessairement bornés à un usage artistique, mais sont également appliqués dans d'autres domaines tels que les communications, quelques hardwares, etc.

Dans cette dissertation, on souligne le processus dans le domaine de l'analyse spectrale $\to$ transformation $\to$ synthèse. On examine, en particulier, la fonctionnalité de l'analyse de Fourier en temps discret avec des fenêtres d'enveloppe variés pour la construction d'un double vocodeur de phase pour réaliser du morphing sonore. Le but artistique consiste à créer un ou plusieurs objets informatiques qui vont servir à la composition d'une pièce acousmatique.

Nous définissons le morphing sonore comme le processus consistant à combiner les spectres de deux sons dans un certain pourcentage, ce qui donne un son hybride contenant des éléments caractéristiques de ceux d'origine. Le terme morphing est également appelé, synthèse croisée, par la suite, les deux termes sont devenus équivalents. Le mécanisme exact de chaque terme, tel que transformation de Fourier, fenêtres d’enveloppe, vocodeur de phase, etc., sera analysé à la section 2.

\subsection{Outils de la réalisation}

Certains commentaires sur les outils utilisés dans cette recherche sont nécessaires avant de discuter des détails de la structure. Comme précédemment mentionné, une recherche interdisciplinaire comme celle-ci exige une collaboration de domaines et de termes issus des mathématiques, de l'informatique et de la musique. Par conséquent, le cadre doit être adapté aux besoins de cette dissertation.

Pour le texte à la place d'un éditeur \textit{WORD} traditionnel, un éditeur de texte \LaTeX{} est utilisé. Ainsi, cette thèse est entièrement écrite en code \LaTeX{}. La nécessité de \LaTeX{} provient de la quantité de formules mathématiques présentées, ainsi que du code joint dans certaines sections. De plus, le code source \LaTeX{} est relativement plus facile à partager et lisible à partir de n’importe quel éditeur de texte. Cependant, l’utilisation de \LaTeX{} rend différemment la formulation de références et la bibliographie en comparaison de la formulation correspondante dans les sciences humaines.

La partie programmation de cette dissertation est presque entièrement codée en Max et Jitter, avec quelques petites parties de code en Javascript. Max est un outil robuste de Cycling74 permettant une analyse et un traitement du signal en temps réel, ainsi que certains traitements visuels. Max Version 7.3.2 est utilisé sans bibliothèques externes. Les paramètres audio sont définis sur SR de 44.100, la taille du vecteur 442 et le vecteur du signal 64. Plus d’informations sur Max sont disponibles à l’adresse suivante: \href{https://cycling74.com/products/max/}{"https://cyclisme74.com"}.

Dernièrement, Reaper a été utilisé pour l'édition du son et l'exportation du format final \guillemotleft .wav\guillemotright. Reaper est, également, utilisé pour le mixage des enregistrements faits dans Max pour orchestrer une composition de courte durrée. Reaper est une platform de travail d'audio numérique (DAW) avec des commandes multicanaux et des options d'enregistrement. Plus d’informations sur Reaper sont disponibles sur \href{https://www.reaper.fm/}{\guillemotleft www.reaper.fm \guillemotright}.

L'archivage de cette recherche est disponible publiquement sur \href{https://github.com/}{\guillemotleft Github.com \guillemotright} où il peut être consulté à des fins d'enseignement ou de recherche. Le lien vers le référentiel Github est disponible sur \href{https://github.com/melkisedeath/Memoire-du-Master-Paris8---Domaines-fondtionnels-du-vocodeur-de-phase}{\guillemotleft github.com/melkisedeath/Memoire-du-Master-Paris8---Domaines-fondtionnels-du-vocodeur-de-phase \guillemotright} sous une licence \textit{MIT}. Dans ce référentiel, on peut trouver le code, les fichiers sonores, la pièce acousmatique en format \textit{wav}, le texte et quelques exemples artistiques.

\section{Structure}

La structure est organisée en trois sections principales. La première section présente toutes les informations techniques nécessaires à la compréhension des fonctionnalités d'un vocodeur de phase. Dans la deuxième section, on construit étape par étape un vocodeur de phase et on se focalise sur le morphing spectral. Dans la dernière section, nous proposons diverses applications artistiques comme suite des résultats de la recherche pour arriver, en fin, à la composition d'une pièce inspiré par le vocodeur de phase.

Plus en détail, la première partie concerne les bases du traitement spectral, tels que l'analyse de Fourier. L’objectif est de faciliter la compréhension des termes complexes du contexte mathématique, afin d’aboutir à une meilleure clarté pour les lecteurs. La transformation de Fourier va nous permettre de comprendre, comment fonctionne la transformation numérique du son. Par conséquent, l'analyse de Fourier fenêtrée sera amplement investiguée. Ces informations sont cruciales pour la compréhension du vocodeur de phase. Les maths derrière le vocodeur de phase sont relativement plus complexes, ainsi donc pour arriver à concevoir comment il fonctionne, il faut utiliser une ramification progressionelle de la formule mathématique principale. Il n'est peut-être pas nécessaire d'entrer dans de tels détails, mais cette connaissance est offerte à d'autres musiciens passionnés de mathématiques qui veulent comprendre la nature sonore.

Après une introduction, plutôt mathématique, l'épreuve de la programmation commence. Max est l'outil clé du traitement du son en temps réel. On va presenter dans Max un guide de construction, étape par étape, d’un vocodeur de phase et en passant par l'exploration mathématique de l'analyse de Fourier, nous allons pénétrer le domaine du morphing spectral. La magie de voir comment une formule mathématique prend vie est l'essence même de la programmation. On peut le constater dès lors qu’on travaille avec des données sonores. On peut entendre un son à plusieurs reprises tout en faisant des modifications. Ce processus mène à une compréhension plus profonde de la fonctionnalité d'un outil informatique sonore. Le morphing spectral, étant l'outil informatique en question, dans cette étude est constitué de deux vocodeurs de phase simultanés qui travaillent sur des entrées différentes.

Il est raisonnable à ce stade de poser la question: est-il nécessaire que quelqu’un soit musicien pour réaliser tout cela? La réponse repose sur l'implementation artistique. Elle sera, donc, la section clé de cette dissertation. En combinant de compétences en programmation, en compréhension mathématique et en créativité musicale, on se rapproche du profile de nombreux compositeurs contemporains. Dans le dernier chapitre, on peut chercher quelques exemples de modèles d'implémentations créatives du vocodeur de phase et, également, une composition à partir le vocodeur. Cette section sera consacré à une investigation sur les differents univers artistiques possibles d'un vocodeur de phase.

\section{Max, MSP et Jitter}

Max est un logiciel développé à l'origine par Michael Puckette sous l'étiquette de l'IRCAM puis acheté par l’entreprise américaine, Cycling74. Le coeur de ce logiciel est construit sur $C++$ et Javascript, traduit dans un environnement d’utilisateur graphique tel que \textit{box connecting}.

Max est essentiellement un langage de programmation, avec chaque rappelle de fonction étant une boîte-code correspondant à une certaine action. Les commandes sont séparées en trois catégories: 
\begin{enumerate}
	\item
	les commandes d'expression logique
	\item
	les commandes du traitement sonore
	\item
	les commandes du traitement des matrices multidimensionnelles	
\end{enumerate}
Chacune correspondant respectivement à Max, MSP et Jitter. L'utilisateur peut connecter diverses commandes des trois catégories pour créer un patch\footnote{Dans Max un fichier code est suivant appelé \guillemotleft patch \guillemotright parmi utilisateurs} complexe. La version la plus récente de Max et Jitter est Max8, publiée en septembre 2018 \footnote{cycling74.com, \textit{Max8 release date}, \href{https://cycling74.com}{https://cycling74.com} \nocite{cycling74}}.

Dans la catégorie du traitement sonore, une librairie spéciale appelée traitement spectral offre à l'utilisateur tous les outils nécessaires pour effectuer une analyse spectrale. La méthode utilisée par Max est appelée transformation rapide de Fourier (FFT). On peut imaginer le signal comme une ligne courbée continue qui est constituée d’une série de points. L'idée est de représenter une somme de ses points par leur contenu harmonique représentative oû, autrement, le diagramme du spectre. Le diagramme du spectre révèle la microstructure des sons vocaux, instrumentaux et synthétiques \footnote{ M. Dolson, \textit{A tracking phase vocoder and its use in the analysis of ensemble sounds}, 1983.\nocite{dolson1983}}.

%L'idée est de convertir un signal qui est une forme à une dimension, en une forme à deux dimensions qui contient essentiellement plus d'informations. On peut couper un fragment de cette ligne du signal et attribuer une valeur à chacun de ses points qui correspondrait à un vecteur dans le plan cartésien. À partir de cette interprétation, il est possible d'extraire des informations de la fréquence et de l'amplitude d’un son.

Outre l'efficacité du traitement spectral et la perception visuelle du logiciel Max est très populaire dans la communauté artistique. Il est utilisé dans une multitude de projets et aussi par des instituts de recherche, tels que l'IRCAM, Paris8, etc. La vaste communauté de Max le rend accessible même aux utilisateurs amateurs. Dernier point, mais non pas des moindres, une série de bibliothèques techniques pour Max, sur les vocodeurs de phase et sur le traitement spectral, est développée par la communauté, démontrant ainsi le rôle principal de ce logiciel. Certaines de ces bibliothèques sont SuperVP, Max SoundBox, etc.

\section{Histoire}

	\subsection{Analyse spectrale}

L'analyse spectrale est le processus qui permette de décomposer un signal en différentes fréquences et leur amplitudes correspondantes. Le produit d'une analyse spectrale s'appelle spectre. La manière standard de réaliser un analyse spectrale est appelée transformation de Fourier \footnote{D. Havelock, S. Kuwano et M. Vorl{\"a}nder, \textit{Handbook of signal processing in acoustics}, 2008, pp. 33-52. \nocite{havelock2008handbook}}. 

Le terme “spectral” a été introduit par Isaak Newton à la fin du 18ème siècle. La théorie de la transformation de Fourier a été formulée en 1822 par Jean Joseph Fourier. Fourier était un physicien qui avait raisonné sur les propriétés thermodynamiques des matériaux. En 1843, Georg Ohm (1789-1854) innova dans le domaine du traitement du signal en appliquant une transformation de Fourier sur des signaux. Par la suite, H. L. F. Helmholtz (1821-1894), en 1863, déclara que le timbre instrumental était largement caractérisé par la série harmonique de Fourier. Dans son livre \textit{The Sensation of Tone}\footnote{H. L. F. Helmholtz, \textit{The Sensation of Tone}, 1863} il décrit des outils mécaniques permettant de reproduire artificiellement le spectre sinusoïdal de divers sons \footnote{ Curtis Roads, \textit{The Computer Music Tutorial}, 1996, p. 545. \nocite{Routes: 1996: CMT: 525484}}.

Les premiers outils qui effectuent l'analyse spectrale numérique apparaissent dans les années 1960 à la suite de la FFT, découverte en 1965 \footnote{J. Cooley et J.W. Tukey, \textit{An algorithm for the machine calculation of complex Fourier series}, 1965. \nocite{Fourier_complex}}. Dans la théorie de Fourier, tout spectre complexe peut être dissous en une série de fréquences simples \footnote{Jean Joseph Baptiste Fourier, \textit{De la Chaleur}, 1822. \nocite{Herm1895}}. Respectivement, chaque son harmonique complexe est constitué d'une somme de simples sinusoïdes d'amplitudes et des fréquences variées.

La transformation de Fourier, signifiant le passage d'un signal continu à son graphe statique fréquentiel, est un concept apprécié dans la plupart des domaines scientifiques. Cependant, il ne faut pas oublier que la transformation est statique. Dans le signal sonore, l'information est continue et variable, c'est l'enjeu principal de la transformation de Fourier. Par conséquent, il convient de considérer la borne supérieure (supremum) de temps nécessaire pour décrire un signal. Ce point précisément fera l’objet d’une discussion approfondie au chapitre suivant.

La fonctionnalité de l'analyse de Fourier sur le son ne repose pas uniquement sur la visualisation des fréquences, mais est utilisée pour divers effets tels que le décalage de hauteur variable, le changement de temps avec une hauteur variable, le traitement du timbre, etc. Ces effets ont conduit au vocodeur de phase, un concept basé sur l'analyse de Fourier d'un signal en fenêtre (FFT). Le but est d’arriver au zénith du vocodeur de phase, qui est le morphing sonore.
		
\begin{quote}
	"Il ne semble pas exister de paradigme général ou optimal afin d'analyser ou synthétiser un son de n'importe quel type. Il faut examiner le son quasi-périodique, la somme des composants inharmoniques, le bruit, l’évolution rapide ou lente, ainsi que les caractéristiques du son pertinentes à l’oreille \footnote{J.C. Risset, \textit{Timbre analysis by synthesis}, 1991 \nocite{risset1991timbre}}". 

	\hfill J.C. Risset
\end{quote}

	\subsection{Le vocodeur de phase}

Le vocodeur de phase, comme son nom l'indique, est un type de vocodeur qui utilise l'information de phase pour traiter les signaux audio. Il est considéré comme un outil de la catégorie \textit{analyse-synthèse}. L'analyse-synthèse concerne les techniques qui analysent des sons et utilisent les données de l'analyse pour synthétiser à nouveau  \footnote{C. Roads, \textit{Musical Signal Processing}, 1996, pp. 31-32. \nocite{Roads97}}. 

Le cœur du vocodeur de phase fonctionne sur la transformation de Fourier à court terme (STFT) telle que la FFT. C'est la transformation typique d'une représentation dans le domaine temporel d'un signal vers le domaine fréquentiel\footnote{Joshua Fineberg, \textit{Guide to the Basic Concepts and Techniques of Spectral Music}, 2000. \nocite{Fin00} }.

L'idée du vocodeur se développe pendant les années 1939 en laboratoires \textit{Bell} par Homer Dudley\footnote{M. Mills, \textit{Media and prosthesis: the vocoder, the artificial larynx, and the history of signal processing}, 2012. \nocite{mills2012media}} . Rapidement, le vocodeur est devenu un outil de la musique électronique de l'époque avec son implémentation dans plusieurs synthétiseurs\footnote{Thom Holmes, \textit{Electronic and experimental music}, 2012. \nocite{holmes2012electronic}}. 

Le vocodeur de phase a été développé en 1966 par Flanagan \footnote{J. L. Flanagan et R. M. Golden, \textit{Phase Vocoder}, 1966. \nocite{flanagan}}. La première version du vocodeur de phase était très chère computantionellement, mais en 1976 une nouvelle méthode a permis de réduire considérablement le prix du calcul. M. Portnoff a construit un nouveau vocodeur de phase qui a intégré la FFT \footnote{M. Portnoff, \textit{Implementation of the digital phase vocoder using the fast Fourier transform}, 1976. \nocite{portnoff1976implementation}}, qui a permis de transformer le vocodeur en outil pratique. Ce développement a conduit vers la première publication sur les applications musicales du vocodeur de phase \footnote{J.A. Moorer, \textit{The synthesis of complex audio spectra by means of discrete summation formulas}, 1976. \nocite{moorer1976synthesis}}. Le compositeur et chercheur, Jean-Claude Risset, a été la première personne à utiliser le vocodeur de phase dans un contexte artistique. Sa collaboration avec les laboratoires Bell dans les années soixante lui a permis d’accéder sur les outils spectraux qui se développe à l'époque \footnote{J.C. Risset, \textit{Computer study of trumpet tones}, 1966. \nocite{risset1966computer}}. 

Bien que le vocodeur de phase a été construit originalement comme une méthode de codage afin de réduire le bande des signaux vocaux \footnote{C. Roads, \textit{The Computer Music Tutorial}, 1996. \nocite{Roads1996}}, son développement vers la version contemporaine était une conséquence de la recherche musicale et la recherche des laboratoires Bell. L’intégration du compositeur J.C. Risset dans les laboratoires Bell et sa relation avec le Groupe des Recherches Musicales (GRM) sont le catalyseur de nombreuses pièces composées avec l'utilisation d'un vocodeur de phase tels que \textit{Computer Suite from Little Boy} (1968), \textit{Mutations} (1969), \textit{Trois moments newtoniens} (1977), \textit{Trois moments newtoniens} (1983)\footnote{V. Tiffon, \textit{Jean-Claude Risset}, 2012. \nocite{RissetParcours}}. Son insatisfaction des outils sonores de l’époque pour la synthèse numérique a conduit au développement du vocodeur de phase.

Cependant, la structure standard du vocodeur de phase moderne a été établie par Griffin et Lim en 1984 \footnote{Daniel W. Griffin et Jae S. Lim, \textit{Signal Estimation from Modified Short-Time Fourier Transform}, 1984. \nocite{GrL84}}. La popularité du vocodeur de phase est établit, comme un outil d'analyse-synthèse, dans les années quatre-vingt-dix avec les premières distributions logiciel\footnote{C. Roads, \textit{The Computer Music Tutorial}, 1996, pp. 566 - 567 \nocite{Roads1996}}. Les applications artistique incluent \textit{Vox Cycle} (1988) par Trevor Wishart\footnote{T. Wishart, \textit{The Composition of Vox 5}, 1988. \nocite{wishart1988composition}}, \textit{Transfigured Wind} (1989) par Roger Reynolds\footnote{X. Serra, \textit{A System for Sound Analysis/Transformation/Synthesis based on Deterministic plus Stochastic Decomposition}, 1989, p. 12. \nocite{serra1989system}}, \textit{Dreampaths} (1989) par JoAnn Kuchera-Morin\footnote{C. Roads, \textit{Microsound}, 2004, p. 318. \nocite{roads2004microsound}}, etc. 

Afin de réduire les artefacts de phase M. Puckette a suggéré d'utiliser le verrouillage de phase pour maintenir la cohérence de phase intacte sur les canaux de fréquence voisins \footnote{M. Puckette, \textit{Phase-locked vocoder}, 1995. \nocite{puckette1995phase}}. Cette méthode a été profondement étudié par Laroche et Dolson qui ont proposé de séparer l’axe des fréquences en régions d’influences\footnote{J. Laroche et M Dolson, \textit{Impoved Phase Vocoder Time-Scale Modification of Audio}, 1999. \nocite{DoLa99}}.

Néanmoins, l'algorithme découvert par Laroche et Dolson n'a pas pu conserver la phase verticale à l’attaque d’un son. Cet effet est connu comme le \textit{transient effet} et il est produit quand un changement soudain et momentané se produit sur la forme d'onde. Cela  correspond à un son d’écho qui n'existe pas sur le son d'origine. En 2003, A. Roebel a proposé une solution à ce problème. Sa méthode consiste à calculer le développement des composants spectrales tout au long du temps pour mieux calculer la préservation des transients pendant des transformations tels que le tirage sonore. De cette manière, le timbre original reste intact sans nuire à la cohérence de phase des partiels stationnaires situés aux fréquences basses\footnote{E.S. Ottosen, \textit{A Phase Vocoder based on Nonstationary Gabor Frames}, 2017. \nocite{ottosen2017phase}}. Les outils SuperVP par \textit{Ircam Tools} et Audiosculpt par \textit{Ircam Tools} sont des exemples de mise en œuvre du vocodeur de phase utilisant la dernière version de Roebel\footnote{Axel Roebel, \textit{A new approach to transient processing in the phase vocoder}, 2003. \nocite{roebel:hal-01161124}}.

Il est considéré comme des exemples d'implémentation logiciel de la transformation du signal basée sur un vocodeur de phase utilisant des moyens similaires à ceux décrits pour obtenir une transformation du signal de haute qualité, les logiciels : SuperVP de l'Ircam\footnote{ \ref{http://anasynth.ircam.fr/home/english/software/supervp}{www.anasynth.ircam.fr}}, Melodyne 4 par Celemony\footnote{ \ref{https://www.celemony.com/en/melodyne/what-is-melodyne}{https://www.celemony.com}}, elastique-PRO par Zplane\footnote{ \ref{https://products.zplane.de/elastique-pitch-2}{https://products.zplane.de/}}, etc. Les vocodeurs de phase modernes, tels que SuperVP, utilisent une approche statistique pour la prédiction de signal, éliminant ainsi tout artefact produit par un traitement sonore peu orthodoxe.

L'histoire de l'évolution du vocodeur ainsi que l'importance de son utilisation dans la musique contemporaine donne, aujourd'hui, un intérêt à la compréhension de l'outil.

\section{Morphing}

Le morphing est le processus d'interpolation entre deux objets ou plus, qui donne un résultat hybride contenant des éléments reconnaissants pour chacune de ses sources. Par cette affirmation, on peut immédiatement énoncer deux concepts: morphing sonore (unidimensionnel) et morphing visuel (multidimensionnel). Dans le son, le résultat est obtenu en combinant les spectres de chaque source avec un certain facteur. Pour les images, le résultat est obtenu en ajoutant les valeurs de pixel de chaque source d’un facteur donné. Si le morphing est assumé sur deux objets, l'un s'appelle objet source et l'autre s'appelle objet target. Objet est un terme attribué à la nature du morphing, qu'elle soit sonore ou visuelle.

    \subsection{Morphing sonore}

Le morphing sonore oû synthèse croisée ne corresponde pas à une seule méthode. Dans ce mémoire on va investiguer le morphing sonore conventionnel produit par un vocodeur de phase. Le morphing sonore entre un son $s_1$ et un son $s_2$ consiste à calculer le produit de leurs composants spectraux. Ce processus est achevé en multipliant chaque composant du spectre de $s_1$ par le composant correspondant du spectre de $s_2$\footnote{C. Roads, \textit{The Computer Music Tutorial}, 1996, pp. 573-576. \nocite{Roads1996}} Autrement, le processus de morphing du son peut être décrit comme une interpolation spectrale entre deux ou plusieurs sources aboutissant à un son hybride morphé contenant des éléments de chaque source. Afin de visualiser la méthode, on peut imaginer une interpolation entre un piano et un violon qui produit un son hybride ayant l'attaque d'un son du piano et la durabilité d'un son de violon.   

Dans le domaine du morphing sonore, il est proposé d’utiliser le concept du vocodeur de phase afin d'obtenir une manipulation du son satisfaisante. Le vocodeur de phase peut être utilisé en temps réel sans perte de qualité et avec un minimum de perte d'informations. Néanmoins, le processus est assez coûteux en calcul, car il nécessite un vocodeur de phase par source sonore.

L'approche du vocodeur de phase pour réaliser le morphing sonore, requiert un minimum de deux vocodeurs de phase. On peut, également, manipuler l'amplitude et la fréquence des sources pour mieux les faire correspondre. Dans cet article, nous suivons les directives du vocodeur SuperVP mais dans une version beaucoup plus simple. Notre approche idéalise l'objet $SuperVP.morph \thicksim $ et tente d'obtenir une paramétrisation plus riche tout au long du processus de sa création. 

L'interpolation générale du vocodeur de phase par IRCAM consiste à combiner les amplitudes et les fréquences instantanées du spectre de deux sons. Soit $f_1(n)$, $A_1(n)$ la fréquence et l'amplitude instantanées pour le premièr son et $f_2(n)$, $A_2(n)$ pour le deuxième, oû $n$ est le numéro de bin. l'amplitude $A'(n)$ et la fréquence $f'(n)$ pour le son produit au bin $n$ sont :
\begin{align*} 
	A'(n) &=  \alpha(n) A_1(n) + \beta(n) A_2(n) + \gamma(n) A_1(n) A_2(n) \\
	f'(n) &=  \delta(n) f_1(n) + \epsilon(n) f_2(n) 
\end{align*}
Oû $\alpha, \beta, \gamma, \delta, \epsilon$ sont des fonctions constantes qui spécifient l'interpolation \footnote{M.H. Serra, \textit{Musical Signal Processing}, 1996, pp. 74-80. \nocite{Roads97}}. 

    \subsection{Morphing visuel}
    
D'autre part, le morphing visuel a une variété d'approches. Premièrement, il convient de séparer les techniques de morphing bidimensionnel de tridimensionnel, où le morphing bidimensionnel est utilisé entre les images et l’interpolation tridimensionnelle entre les formes. Bien sûr, le morphing peut être envisagé pour des formes de dimensions supérieures, mais le résultat semble rélativement plus difficile à appréhender.

À partir du morphing en 3 dimensions, on entend l'interpolation de la position des sommets. Pour visualiser l'effet, imaginons deux formes 3D, par exemple une sphère et un cube. La forme est composée soit d'une somme de points, soit d'une somme de simplices à deux dimensions. De plus, il existe d'autres méthodes qui ne sont pas si courantes et, par conséquent, elle sont omises. Les deux formes doivent avoir le même nombre de points / simplices. Le morphing entre les formes correspond au changement de la position de chaque point / simplex de la forme source vers la position de chaque point / simplex de la forme target. Bien sûr, le morphing bidimensionnel peut être envisagé sur des formes, mais il ne s'agit que d'une perception de l'orientation sur des formes 3D. La méthode est donc exactement la même.

Le morphing de l'image est plus complexe. Le simple moyen d’ajouter les valeurs de pixels avec un facteur de pourcentage est une méthode valide sans résultats intéressants. La solution intelligente consiste à utiliser des VAE (Variational Auto-Encoders). C'est une méthode basée sur l'apprentissage automatique utilisant les fameux réseaux génératifs adversarials (GANs). Les GANs sont des architectures de réseaux neuronaux composées de deux réseaux l’un opposé à l’autre \footnote{Goodfellow, Pouget-Abadie, Mirza, Xu, Warde-Farley, Ozeir, Courvill, Bengio. \textit{Generative Adversarial Networks.} 2004. \nocite{GANs}}. Ce mémoire se concentre sur le son, et par conséquent, le morphing de l'image ne sera pas examiné.


   
