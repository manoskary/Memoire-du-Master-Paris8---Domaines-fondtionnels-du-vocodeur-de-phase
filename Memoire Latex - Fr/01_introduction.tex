
\section{À propos}

De nos jours, la musique est devenue un vaste sujet de recherche scientifique. Les branches de la musique se développent à travers divers domaines tels que, l'analyse musicale mélangée avec la modélisation mathématique, l’histoire avec l’ethnomusicologie, l’acoustique avec la physique, la composition avec la programmation, etc. En empruntant cette voie interdisciplinaire, on va lier la musique aux autres sciences, afin ainsi de progresser vers un nouveau point de vue et de présenter des résultats innovants.

Dans la branche de la composition musicale, l’étude de la nature du son a été spécialement développée en produisant diverses techniques guidées par des phénomènes physiques. Une série d'outils de traitement du son basés sur des phénomènes physiques sont étiquetés sous une branche appelée analyse-synthèse du son. Dans cette branche, un ensemble de disciplines scientifiques se contracte dans un seul but, de comprendre la musique et la nature sonore. À travers l’analyse sonore, nous procédons à la synthèse. De la science nous alons vers l'art. Le nom d'analyse-synthèse exprime ce principe, d’observation (analyse). Cela permet de procéder au traitement du son et aboutir à un nouveau produit sonore (synthèse). Le nom, est traduit littérairement au traitement spectral, où l’étape d’analyse transfère un son du domaine temporel au domaine fréquentiel. L'analyse présente les informations spectrales d'un son à une certaine période du temps. L'outil de synthèse inverse le processus, il transfère le son du domaine fréquentiel vers le domaine temporel, ce qui produit comme résultat, la forme de signal d'onde conventionnelle.

Les outils d'analyse-synthèse sont initialement conçus pour aider les compositeurs ou les artistes en particulier de la composition contemporaine. Ils peuvent servir notamment, pour l'utilisation de séquences générées par l’ordinateur sur les œuvres de Stockhousen ou bien pour l’analyse spectrale assistée par ordinateur pour répondre aux besoins des compositeurs spectraux, tel que Gerard Grisey, Tristan Murail, etc. Pour autant, les résultats ou les techniques ne sont pas nécessairement bornés à un usage artistique, mais sont également appliqués dans d'autres domaines tels que les communications, quelques hardwares, etc.

Dans cette dissertation, on souligne le processus dans le domaine de l'analyse spectrale $\to$ transformation $\to$ synthèse. On examine, en particulier, la fonctionnalité de l'analyse de Fourier en temps discret avec des fenêtres d'enveloppe variés pour la construction d'un double vocodeur de phase pour réaliser du morphing sonore. Le but artistique consiste à créer un ou plusieurs objets informatiques qui vont servir à la composition d'une pièce acousmatique.

Nous définissons le morphing sonore comme le processus consistant à combiner les spectres de deux sons dans un certain pourcentage, ce qui donne un son hybride contenant des éléments caractéristiques de ceux d'origine. Le terme morphing est également appelé, synthèse croisée, par la suite, les deux termes sont devenus équivalents. Le mécanisme exact de chaque terme, tel que transformée de Fourier, fenêtres d’enveloppe, vocodeur de phase, etc., sera analysé à la section 2.

\subsection{Outils de la réalisation}

Certains commentaires sur les outils utilisés dans cette recherche sont nécessaires avant de discuter des détails de la structure. Comme précédemment mentionné, une recherche interdisciplinaire comme celle-ci exige une collaboration de domaines et de termes issus des mathématiques, de l'informatique et de la musique. Par conséquent, le cadre doit être adapté aux besoins de cette dissertation.

Pour le texte à la place d'un éditeur \textit{WORD} traditionnel, un éditeur de texte \LaTeX{} est utilisé. Ainsi, cette thèse est entièrement écrite en code \LaTeX{}. La nécessité de \LaTeX{} provient de la quantité de formules mathématiques présentées, ainsi que du code joint dans certaines sections. De plus, le code source \LaTeX{} est relativement plus facile à partager et lisible à partir de n’importe quel éditeur de texte. Cependant, l’utilisation de \LaTeX{} rend différemment la formulation de références et la bibliographie en comparaison des normes françaises.

La partie programmation de cette dissertation est presque entièrement codée en MaxMSP et Jitter, avec quelques petites parties de code en Javascript. Max est un outil robuste de Cycling74 permettant une analyse et un traitement du signal en temps réel, ainsi que certains traitements visuels. Max Version 7.3.2 est utilisé sans bibliothèques externes. Les paramètres audio sont définis sur SR de 44.100, la taille du vecteur 442 et le vecteur du signal 64. Plus d’informations sur MaxMSP sont disponibles à l’adresse suivante: \href{https://cycling74.com/products/max/}{"https://cyclisme74.com"}.

Dernièrement, Reaper a été utilisé pour l'édition du son et l'exportation du format final \guillemotleft .wav\guillemotright. Reaper est, également, utilisé pour le mixage des enregistrements faits dans Max pour orchestrer une composition de courte durrée. Reaper est une platform de travail d'audio numérique (DAW) avec des commandes multicanaux et des options d'enregistrement. Plus d’informations sur Reaper sont disponibles sur \href{https://www.reaper.fm/}{\guillemotleft www.reaper.fm \guillemotright}.

L'archivage de cette recherche est disponible publiquement sur \href{https://github.com/}{\guillemotleft Github.com \guillemotright} où il peut être consulté à des fins d'enseignement ou de recherche. Le lien vers le référentiel Github est disponible sur \href{https://github.com/melkisedeath/Memoire-du-Master-Paris8---Domaines-fondtionnels-du-vocodeur-de-phase}{\guillemotleft github.com/melkisedeath/Memoire-du-Master-Paris8---Domaines-fondtionnels-du-vocodeur-de-phase \guillemotright} sous une licence \textit{MIT}. Dans ce référentiel, on peut trouver le code, les fichiers sonores, la pièce acousmatique en format \textit{wav}, le texte et quelques exemples artistiques.

\section{Structure}

La structure est organisée en trois sections principales. La première section présente toutes les informations techniques nécessaires à la compréhension des fonctionnalités d'un vocodeur de phase. Dans la deuxième section, on construit étape par étape un vocodeur de phase et on se focalise sur le morphing spectral. Dans la dernière section, nous proposons diverses applications artistiques comme suite des résultats de la recherche pour arriver, en fin, à la composition d'une pièce inspiré par le vocodeur de phase.

Plus en détail, la première partie concerne les bases du traitement spectral, tels que l'analyse de Fourier. L’objectif est de faciliter la compréhension des termes complexes du contexte mathématique, afin d’aboutir à une meilleure clarté pour les lecteurs. La transformation de Fourier va nous permettre de comprendre, comment fonctionne la transformation numérique du son. Par conséquent, l'analyse de Fourier fenêtrée sera amplement investiguée. Ces informations sont cruciales pour la compréhension du vocodeur de phase. Les maths derrière le vocodeur de phase sont relativement plus complexes, ainsi donc pour arriver à concevoir comment il fonctionne, il faut utiliser une ramification progressionelle de la formule mathématique principale. Il n'est peut-être pas nécessaire d'entrer dans de tels détails, mais cette connaissance est offerte à d'autres musiciens passionnés de mathématiques qui veulent comprendre la nature sonore.

Après une introduction, plutôt mathématique, l'épreuve de la programmation commence. MaxMSP est l'outil clé du traitement du son en temps réel. On va presenter dans Max un guide de construction, étape par étape, d’un vocodeur de phase et en passant par l'exploration mathématique de l'analyse de Fourier, nous allons pénétrer le domaine du morphing spectral. La magie de voir comment une formule mathématique prend vie est l'essence même de la programmation. On peut le constater dès lors qu’on travaille avec des données sonores. On peut entendre un son à plusieurs reprises tout en faisant des modifications. Ce processus mène à une compréhension plus profonde de la fonctionnalité d'un outil informatique sonore. Le morphing spectral, étant l'outil informatique en question, dans cette étude est constitué de deux vocodeurs de phase simultanés qui travaillent sur des entrées différentes.

Il est raisonnable à ce stade de poser la question: est-il nécessaire que quelqu’un soit musicien pour réaliser tout cela? La réponse repose sur l'implementation artistique. Elle sera, donc, la section clé de cette dissertation. En combinant de compétences en programmation, en compréhension mathématique et en créativité musicale, on se rapproche du profile de nombreux compositeurs contemporains. Dans le dernier chapitre, on peut chercher quelques exemples de modèles d'implémentations créatives du vocodeur de phase et, également, une composition à partir le vocodeur. Cette section sera consacré à une investigation sur les differents univers artistiques possibles d'un vocodeur de phase.

\section{MaxMSP et Jitter}

MaxMSp est un logiciel développé à l'origine par Michael Puckette sous l'étiquette de l'IRCAM puis acheté par l’entreprise américaine, Cycling74. Le coeur de ce logiciel est construit sur $C++$ et Javascript, traduit dans un environnement d’utilisateur graphique tel que \textit{box connecting}.

MaxMSP est essentiellement un langage de programmation, avec chaque rappelle de fonction étant une boîte-code correspondant à une certaine action. Les commandes sont séparées en trois catégories: 
\begin{enumerate}
	\item
	les commandes d'expression logique
	\item
	les commandes du traitement sonore
	\item
	les commandes du traitement des matrices multidimensionnelles	
\end{enumerate}
Chacune correspondant respectivement à Max, MSP et Jitter. L'utilisateur peut connecter diverses commandes des trois catégories pour créer un patch\footnote{Dans Max un fichier code est suivant appelé \guillemotleft patch \guillemotright parmi utilisateurs} complexe. La version la plus récente de MaxMSP et Jitter est Max8, publiée en septembre 2018 \footnote{cycling74.com, \textit{Max8 release date}, \href{https://cycling74.com}{https://cycling74.com} \nocite{cycling74}}.

Dans la catégorie du traitement sonore, une librairie spéciale appelée traitement spectral offre à l'utilisateur tous les outils nécessaires pour effectuer une analyse spectrale. La méthode utilisée par MaxMSP est appelée transformation rapide de Fourier (FFT). On peut imaginer le signal comme une ligne courbée continue qui est constituée d’une série de points. L'idée est de convertir un signal qui est une forme à une dimension, en une forme à deux dimensions qui contient essentiellement plus d'informations. On peut couper un fragment de cette ligne du signal et attribuer une valeur à chacun de ses points qui correspondrait à un vecteur dans le plan cartésien. À partir de cette interprétation, il est possible d'extraire des informations de la fréquence et de l'amplitude d’un son.

Outre l'efficacité du traitement spectral et de la perceptivité visuelle du logiciel MaxMSP est très populaire dans la communauté artistique. Il est utilisé dans une multitude de projets et aussi par des instituts de recherche, tels que l'IRCAM, Paris8, etc. La vaste communauté de Max le rend accessible même aux utilisateurs amateurs. Dernier point, mais non pas des moindres, une série de bibliothèques techniques pour Max, sur les vocodeurs de phase et sur le traitement spectral, est développée par la communauté, démontrant ainsi le rôle principal de ce logiciel. Certaines de ces bibliothèques sont SuperVP, Max SoundBox, etc.

\section{Analyse spectrale}

L'analyse spectrale est le processus de mesure du spectre d'un certain signal. Le spectre contient des informations sur la phase et la magnitude à partir desquelles on peut extraire un diagramme appelé graphe fréquence-magnitude. Dans un tel diagramme, on peut visualiser les fréquences d’un signal et leurs amplitudes correspondantes, pendant une certaine période temporele.

	\subsection{Histoire}

Le terme “spectral” a été introduit par Isaak Newton à la fin du 18ème siècle. La théorie de la transformation de Fourier a été formulée en 1822 par Jean Joseph Fourier. Fourier était un physicien qui avait raisonné sur les propriétés thermodynamiques des matériaux. En 1843, Georg Ohm (1789-1854) innova dans le domaine du traitement du signal en appliquant une transformée de Fourier sur des signaux. Par la suite, H. L. F. Helmholtz (1821-1894) déclara que le timbre instrumental était largement caractérisé par la série harmonique de Fourier en 1863. Dans son livre \textit{The Sensation of Tone}\footnote{H. L. F. Helmholtz, \textit{The Sensation of Tone}, 1863} il décrit des outils mécaniques permettant de reproduire artificiellement le spectre sinusoïdal de divers sons \footnote{ Curtis Roads, \textit{The Computer Music Tutorial}, 1996. [p. 545] \nocite{Routes: 1996: CMT: 525484}}.

Les premiers analyseurs de spectre numériques apparaissent dans les années 1960 à la suite de la FFT, découverte en 1965. Dans la théorie de Fourier, tout spectre complexe peut être dissous en une série de fréquences simples \footnote{Jean Joseph Baptiste Fourier, \textit{De la Chaleur}, 1822. \nocite{Herm1895}}. Respectivement, chaque son harmonique complexe est constitué d'une somme de simples sinusoïdes d'amplitudes variées.

La transformation de Fourier, signifiant le passage d'un signal continu à son graphe statique fréquence-magnitude, est un concept apprécié dans la plupart des domaines scientifiques. Cependant, il ne faut pas oublier que la transformation est statique. Dans le signal sonore, l'information est continue et variable. C'est l'enjeu principal de la transformation de Fourier. Par conséquent, il convient de considérer la borne supérieure (supremum) de temps nécessaire pour décrire un signal. Ce point précisément fera l’objet d’une discussion approfondie au chapitre suivant.

La fonctionnalité de l'analyse de Fourier sur le son ne repose pas uniquement sur la visualisation des fréquences, mais est utilisée pour divers effets tels que le décalage de hauteur variable, le changement de temps avec une hauteur variable, le traitement du timbre, etc. Ces effets ont conduit au vocodeur de phase, un concept basé sur l'analyse de Fourier d'un signal en fenêtre (FFT). Le but est d’arriver au zénith du vocodeur de phase, qui est le morphing sonore.

	\subsection{Le vocodeur de phase}

Le vocodeur de phase, comme son nom l'indique, est un type de vocodeur qui utilise l'information de phase pour traiter les signaux audio. Le coeur du vocodeur de phase fonctionne sur la transformation de Fourier à court terme (STFT) telle que la FFT. C'est la transformation typique d'une représentation dans le domaine temporel d'un signal dans le domaine fréquence-magnitude\footnote{Joshua Fineberg, \textit{Guide to the Basic Concepts and Techniques of Spectral Music}, 2000. \nocite{Fin00} }.

Le vocodeur de phase a été découvert en 1966 par Flanagan \footnote{J. L. Flanagan et R. M. Golden, \textit{Phase Vocoder}, 1966. \nocite{flanagan}}. Cependant, la structure standard du vocodeur de phase moderne a été établie par Griffin et Lim en 1984 \footnote{Daniel W. Griffin et Jae S. Lim, \textit{Signal Estimation from Modified Short-Time Fourier Transform}, 1984. \nocite{GrL84}}. Un exemple d'implémentation logicielle de la transformation du signal basée sur un vocodeur de phase utilisant des moyens similaires à ceux décrits pour obtenir une transformation du signal de haute qualité est le logiciel SuperVP de l'Ircam \footnote{ \ref{http://anasynth.ircam.fr/home/english/software/supervp}{www.anasynth.ircam.fr}}. Les vocodeurs de phase modernes, tels que SuperVP, utilisent une approche statistique pour la prédiction de signal, éliminant ainsi tout artefact produit par un traitement sonore peu orthodoxe.

\section{Morphing}

Le morphing est le processus d'interpolation entre deux objets ou plus, qui donne un résultat hybride contenant des éléments reconnaissants pour chacune de ses sources. Par cette affirmation, on peut immédiatement énoncer deux concepts: morphing sonore (unidimensionnel) et morphing visuel (multidimensionnel). Dans le son, le résultat est obtenu en combinant les spectres de chaque source avec un certain facteur. Pour les images, le résultat est obtenu en ajoutant les valeurs de pixel de chaque source d’un facteur donné. Si le morphing est assumé sur deux objets, l'un s'appelle objet source et l'autre s'appelle objet target. Objet est un terme attribué à la nature du morphing, quelle soit sonore ou visuelle.

    \subsection{Morphing sonore}
    
Le morphing sonore combine des spectres de sons ce qui entraine une interpolation des deux facteurs, fréquence et magnitude. On rappelle que dans le vocodeur de phase, la fréquence est calculée par rapport à la phase. Le processus de morphing du son peut être décrit comme une interpolation spectrale entre deux ou plusieurs sources aboutissant à un son hybride morphé contenant des éléments de chaque source. On peut citer comme exemple, un morphing entre un piano et un violon qui jouent tout le deux une note à 440Hz aurait une attaque percutante du piano et une queue riche et stable correspondante au spectre du violon.

Dans le domaine du morphing sonore, il est proposé d’utiliser le concept du vocodeur de phase afin d'obtenir une manipulation du son satisfaisante. Le vocodeur de phase peut être utilisé en temps réel sans perte de qualité et avec un minimum de perte d'informations. Néanmoins, le processus est assez coûteux en calcul, car il nécessite un vocodeur de phase par source sonore.

Avec une approche d'un vocodeur de phase pour réaliser du morphing sonore, un minimum de deux vocodeurs de phase est requis. On peut, également, manipuler l'amplitude et la fréquence des sources pour mieux les faire correspondre. Dans cet article, nous suivons les directives du vocodeur SuperVP mais dans une version beaucoup plus simple. Notre approche idéalise l'objet $SuperVP.morph \thicksim $ et tente d'obtenir une paramétrisation plus riche tout au long du processus de sa création.

        
    \subsection{Morphing visuel}
    
D'autre part, le morphing visuel a une variété d'approches. Premièrement, il convient de séparer les techniques de morphing bidimensionnel de tridimensionnel, où le morphing bidimensionnel est utilisé entre les images et l’interpolation tridimensionnelle entre les formes. Bien sûr, le morphing peut être envisagé pour des formes de dimensions supérieures, mais le résultat semble rélativement plus difficile à appréhender.

À partir du morphing en 3 dimensions, on entend l'interpolation de la position des sommets. Pour visualiser l'effet, imaginons deux formes 3D, par exemple une sphère et un cube. La forme est composée soit d'une somme de points, soit d'une somme de simplices à deux dimensions. De plus, il existe d'autres méthodes qui ne sont pas si courantes et, par conséquent, elle sont omises. Les deux formes doivent avoir le même nombre de points / simplices. Le morphing entre les formes correspond au changement de la position de chaque point / simplex de la forme source vers la position de chaque point / simplex de la forme target. Bien sûr, le morphing bidimensionnel peut être envisagé sur des formes, mais il ne s'agit que d'une perception de l'orientation sur des formes 3D. La méthode est donc exactement la même.

Le morphing de l'image est plus complexe. Le simple moyen d’ajouter les valeurs de pixels avec un facteur de pourcentage est une méthode valide sans résultats intéressants. La solution intelligente consiste à utiliser des VAE (Variational Auto-Encoders). C'est une méthode basée sur l'apprentissage automatique utilisant les fameux réseaux génératifs adversarials (GANs). Les GANs sont des architectures de réseaux neuronaux composées de deux réseaux l’un opposé à l’autre \footnote{Goodfellow, Pouget-Abadie, Mirza, Xu, Warde-Farley, Ozeir, Courvill, Bengio. \textit{Generative Adversarial Networks.} 2004. \nocite{GANs}}. Ce mémoire se concentre sur le son, et par conséquent, le morphing de l'image ne sera pas examiné.


   
